{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite3 import connect\n",
    "\n",
    "# from datetime import datetime\n",
    "import json\n",
    "from webbrowser import get\n",
    "\n",
    "# from requests.auth import HTTPBasicAuth\n",
    "import configuration_class\n",
    "import subprocess\n",
    "import os \n",
    "import sys\n",
    "import shutil\n",
    "import logging\n",
    "from io import StringIO\n",
    "\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from airflow.hooks.base_hook import BaseHook\n",
    "# to last_success_date_epoch needen\n",
    "from dateutil.parser import *   \n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_failde_pods = configuration_class.OpenShiftPodsMonitoring()\n",
    "monitoring_failed_pods_data_pipeline = monitoring_failde_pods.MONITORING_FAILED_PODS_DATA_PIPELINE_MONITORING_PROD_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_dates_hours(date1):\n",
    "    now = dt.datetime.now()\n",
    "    beauty_time = now.strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "    beauty_time = dt.datetime.strptime(beauty_time,\"%Y-%m-%d  %H:%M:%S\")\n",
    "    delta = (beauty_time - date1).total_seconds()\n",
    "    min = delta / 60\n",
    "    hours = delta / (60 * 60) \n",
    "    # print( f''' JESTEM W differences_dates_hours now = {type(beauty_time) } - {beauty_time}  DATE1 = {type(date1)} , {date1} \n",
    "    #       \\n delta = {type(delta)}   {delta}  min = {min}   hours = {hours}''')\n",
    "    \n",
    "    return round(hours,2)\n",
    "   \n",
    "def difference_dates_minutes(date1 ):\n",
    "    now = dt.datetime.now()\n",
    "    beauty_time = now.strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "    beauty_time = dt.datetime.strptime(beauty_time,\"%Y-%m-%d  %H:%M:%S\")\n",
    "    delta = (beauty_time - date1).total_seconds()\n",
    "    min = delta / 60 \n",
    "    # hours = delta / (60 * 60) \n",
    "    # print( f''' JESTEM W differences_dates_hours now = {type(beauty_time) } - {beauty_time}  DATE1 = {type(date1)} , {date1} \n",
    "    #       \\n delta = {type(delta)}   {delta}  min = {min}   hours = {hours}''')\n",
    "    \n",
    "    return round(min,2)\n",
    "    \n",
    "def difference_dates_seconds(date1):\n",
    "    now = dt.now()\n",
    "    beauty_time = now.strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "    beauty_time = dt.datetime.strptime(beauty_time,\"%Y-%m-%d  %H:%M:%S\")\n",
    "    delta = (beauty_time - date1).total_seconds()\n",
    "    # min = delta / 60\n",
    "    # hours = delta / (60 * 60) \n",
    "    # print( f''' JESTEM W differences_dates_hours now = {type(beauty_time) } - {beauty_time}  DATE1 = {type(date1)} , {date1} \n",
    "    #       \\n delta = {type(delta)}   {delta}  min = {min}   hours = {hours}''')\n",
    "    \n",
    "    return delta\n",
    "def change_creationtimestamp(date):\n",
    "        date = dt.datetime.fromisoformat(date[:-1] + '+00:00')\n",
    "        new_time = date + dt.timedelta(hours=2) \n",
    "        new_time = new_time.strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "        return dt.datetime.strptime(new_time,\"%Y-%m-%d  %H:%M:%S\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date string to epoch converter:\n",
      "input: 2022-08-17T07:40:00Z\n",
      "2022-08-17 07:40:00\n",
      "date to epoch converter return: 1660722000000\n",
      "1660722000000\n",
      "date string to epoch converter:\n",
      "input: 2022-09-13T14:13:42Z\n",
      "2022-09-13 14:13:42\n",
      "date to epoch converter return: 1663078422000\n",
      "1663078422000\n",
      "date string to epoch converter:\n",
      "input: 2022-08-17T07:40:00\n",
      "2022-08-17 07:40:00\n",
      "date to epoch converter return: 1660722000\n",
      "Unix_Time => 1660722000\n",
      "Date & Time => <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "def date_to_epoch(date_input, in_seconds=False):\n",
    "    ''' \n",
    "    INPUT: date as a datetime object, or as a string - then formats accepted are like '2022-07-07T08:00:00', '2022-07-07T08:00:00+00:00', '2022-07-07T08:00:00-02:00', '2022-07-07 08:00:00,100', '2022-07-07T08:00:00.100z', 'Jul 7, 2022 @ 08:00:00.683' etc.\n",
    "    IMPORTANT: if input date is NAIVE, it is treated like it is in UTC\n",
    "    OUTPUT: unix timestamp (epoch time). Default in miliseconds, in seconds if the second parameter = True\n",
    "    '''\n",
    "\n",
    "    print('date string to epoch converter:')\n",
    "    print('input: '+str(date_input))\n",
    "\n",
    "    if type(date_input) == str:\n",
    "        if '@' in date_input:\n",
    "            date_input = date_input.replace(\"@\", \"\")\n",
    "        date = parse(date_input)\n",
    "    else:\n",
    "        date = date_input\n",
    "\n",
    "    epoch = calendar.timegm(date.utctimetuple())\n",
    "    print(dt.datetime.utcfromtimestamp(epoch).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    if in_seconds == False:\n",
    "        epoch = epoch*1000\n",
    "    print('date to epoch converter return: '+str(epoch))\n",
    "    return epoch\n",
    "\n",
    "\n",
    "print( date_to_epoch('2022-08-17T07:40:00Z'))\n",
    "print( date_to_epoch('2022-09-13T14:13:42Z'))\n",
    "\n",
    "a = date_to_epoch('2022-08-17T07:40:00', True )\n",
    "b = dt.datetime.fromtimestamp(a) \n",
    "print(\"Unix_Time =>\",a)\n",
    "print(\"Date & Time =>\" ,    type( b.strftime('%Y-%m-%d %H:%M:%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res  <Response [200]>\n",
      "folders  <Response [200]>\n",
      "dashboards  <Response [200]>\n",
      "get_forder_by_id  <Response [200]>\n",
      "1000 , \n",
      "  {'id': 6221, 'uid': 'PxXOwGa7k', 'title': 'ACC', 'uri': 'db/acc', 'url': '/dashboards/f/PxXOwGa7k/acc', 'slug': '', 'type': 'dash-folder', 'tags': [], 'isStarred': False, 'sortMeta': 0} \n",
      " keys of res dict_keys(['id', 'uid', 'title', 'uri', 'url', 'slug', 'type', 'tags', 'isStarred', 'sortMeta'])\n",
      "85 , \n",
      "  [{'id': 6221, 'uid': 'PxXOwGa7k', 'title': 'ACC'}, {'id': 675, 'uid': 't39yCXxZk', 'title': 'AD-Labeling'}, {'id': 988, 'uid': 'EHNfu23Zk', 'title': 'Airflow'}] \n",
      " keys of res dict_keys(['id', 'uid', 'title'])\n",
      "\n",
      " \n",
      " ---- \n",
      " \n",
      " <class 'dict'> , \n",
      "  {'id': 778, 'uid': 'ZsM-EZyZk', 'title': 'Boson', 'url': '/dashboards/f/ZsM-EZyZk/boson', 'hasAcl': False, 'canSave': False, 'canEdit': False, 'canAdmin': False, 'createdBy': 'admin', 'created': '2020-01-20T07:40:36Z', 'updatedBy': 'bartlomiej.grzeskowiak@dxc.com', 'updated': '2021-12-02T14:20:36Z', 'version': 2} \n",
      " keys of res dict_keys(['id', 'uid', 'title', 'url', 'hasAcl', 'canSave', 'canEdit', 'canAdmin', 'createdBy', 'created', 'updatedBy', 'updated', 'version'])\n"
     ]
    }
   ],
   "source": [
    "def get_grafana_dashboards():\n",
    "    TOKEN = \"eyJrIjoiejdFN3hSZ3pva2kwYVE3Mmg0ek1Gc3dxNlh0OWhlUUQiLCJuIjoicmFkZWsiLCJpZCI6Mn0=\"\n",
    "    connection = {\n",
    "        \"proxies\" : {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'},\n",
    "        \"token\" : TOKEN,\n",
    "        \"headers\" : {'Accept': 'application/json',\"Authorization\": \"Bearer \"+ TOKEN},\n",
    "        \"link\"    : \"https://grafana-centralized-monitoring.advantagedp.org/api/search\",\n",
    "        \"link0\"   : \"https://grafana-centralized-monitoring.advantagedp.org/api/folders\",\n",
    "        \"link_db\" : \"https://grafana-centralized-monitoring.advantagedp.org/api/folders/ZsM-EZyZk\", # folder\n",
    "        \"linkf\"   : \"https://grafana-centralized-monitoring.advantagedp.org/api/folders/id/778\",\n",
    "        \"link_search\" : \"https://grafana-centralized-monitoring.advantagedp.org/api/search?query=&\",\n",
    "        \"link_json\"   : \"https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/\"\n",
    "  \n",
    "\n",
    "    }\n",
    "#     mkdir -p dashboards && for dash in $(curl -k -H \"Authorization: Bearer $KEY\" $HOST/api/search\\?query\\=\\& |tr ']' '\\n' |cut -d \",\" -f 5 |grep slug |cut -d\\\" -f 4); do \n",
    "#   curl -k -H \"Authorization: Bearer $KEY\" $HOST/api/dashboards/db/$dash > dashboards/$dash.json \n",
    "# done\n",
    "    res = requests.get(connection['link'], headers=connection['headers'], proxies=connection['proxies'], verify=False)\n",
    "    folders = requests.get(connection['link0'], headers=connection['headers'], proxies=connection['proxies'], verify=False)\n",
    "    dashboards = requests.get(connection['link_db'], headers=connection['headers'], proxies=connection['proxies'], verify=False)\n",
    "    get_forder_by_id = requests.get(connection['linkf'], headers=connection['headers'], proxies=connection['proxies'], verify=False)\n",
    "\n",
    "    print( 'res ',res )\n",
    "    print( 'folders ',folders )\n",
    "    print( 'dashboards ',dashboards )\n",
    "    print( 'get_forder_by_id ',get_forder_by_id )\n",
    "\n",
    "    res = res.json()\n",
    "    folders = folders.json()\n",
    "    dashboards = dashboards.json()\n",
    "    get_forder_by_id = get_forder_by_id.json()\n",
    "\n",
    "    # res_db = res_db.json()\n",
    "    # print( f'res_db 0     {res_db}')\n",
    "    print( f'{len(res)} , \\n  {res[0]} ')\n",
    "    print( f' keys of res {res[0].keys()}')\n",
    "    print( f'{len(folders)} , \\n  {folders[0:3]} ')\n",
    "    print( f' keys of res {folders[0].keys()}')\n",
    "    print( f'\\n \\n ---- \\n \\n {type(dashboards)} , \\n  {dashboards} ')\n",
    "    print( f' keys of res {dashboards.keys()}')\n",
    "    # for key , item in dashboards.items():\n",
    "    #     print(f' klucz {key} --  {dashboards[key]}')\n",
    "    # print( f' \\n  ==== \\n {type(get_forder_by_id)} , \\n  {get_forder_by_id.keys()}')\n",
    "    # for key , item in get_forder_by_id.items():\n",
    "    #     print(f' klucz {key} --  {get_forder_by_id[key]}')\n",
    "\n",
    "    id,uid, title, uri,url, slug, type_ ,tags, isStarred, sortMeta = zip(# title, uri, url, slug, type, tags, isStarred, sortMeta = zip(\n",
    "        *(\n",
    "            (\n",
    "                item[\"id\"],\n",
    "                item[\"uid\"],\n",
    "                item[\"title\"],\n",
    "                item[\"uri\"],\n",
    "                item[\"url\"],\n",
    "                item[\"slug\"],\n",
    "                item[\"type\"],\n",
    "                item[\"tags\"],\n",
    "                item[\"isStarred\"],\n",
    "                item[\"sortMeta\"],\n",
    "                \n",
    "            )\n",
    "            for item in res\n",
    "        )\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Id\": id,\n",
    "            \"Uid\": uid,\n",
    "            \"Title\": title,\n",
    "            \"Uri\": uri,\n",
    "            \"Url\": url,\n",
    "            \"Slug\": slug,\n",
    "            \"Type\": type_,\n",
    "            \"Tags\": tags,\n",
    "            \"IsStarred\": isStarred,\n",
    "            \"SortMeta\": sortMeta,\n",
    "        }\n",
    "    )\n",
    "    # print(  df[0:15:2] ) \n",
    "    # print( df.iloc[12])\n",
    "    # boson = df.iloc[12]\n",
    "    return df\n",
    "all_dashboardy = get_grafana_dashboards()    \n",
    "boson_dashboards = all_dashboardy.loc[12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10 19\n"
     ]
    }
   ],
   "source": [
    "today = dt.datetime.now()\n",
    "print( today.year, today.month, str(today.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1473/1691221298.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boson['Name'] = boson['Title'].apply( lambda x : x.replace(\" \",\"_\"))\n",
      "/tmp/ipykernel_1473/1691221298.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boson['Links'] = boson['Uid'].apply( make_link)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10 19\n",
      "['15_37_plik.txt', 'pody_datapipeline.json', 'res', 'Monitoring_for_Data_Pipeline.json', 'a.py', 'Monitoring_for_Ingest_Service_application.json', 'Monitoring_for_failed_pods_OCP.json', '__pycache__', 'aaa.json', '15_37_condola2.txt', 'configuracja.py', 'Boson_2022_10_19', 'Monitoring_for_Copy_Processes.json', 'restAPI_exercise.ipynb:Zone.Identifier', 'restapi_FAILDE_PODS.ipynb', 'restapi_ALL.ipynb', 'a.ipynb', 'restAPI_exercise.ipynb', 'reingest.txt', 'configuration_class.py', 'restapi_FAILED_PODS.py', 'api1.py', 'bbbb.txt', 'grafa.json', 'Monitoring_for_Copy_Processes_Copy.json', 'Monitoring_for_Session_Checker_application.json', '.vscode', 'Monitoring_for_FOT_application.json', '15_37_konsola.txt', 'bbbb.json', 'restapi_openshift.ipynb', 'Boson_2022_10_18', 'KPI_806.json', 'reingest2.txt', 'rest_api1.ipynb']\n",
      " DIRECTORIE Boson_2022_10_19 EXISTS \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1473/1691221298.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boson['Name'] = boson['Title'].apply( lambda x : x.replace(\" \",\"_\"))\n",
      "/tmp/ipykernel_1473/1691221298.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boson['Links'] = boson['Uid'].apply( make_link)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10 19\n",
      "['15_37_plik.txt', 'pody_datapipeline.json', 'res', 'Monitoring_for_Data_Pipeline.json', 'a.py', 'Monitoring_for_Ingest_Service_application.json', 'Monitoring_for_failed_pods_OCP.json', '__pycache__', 'aaa.json', '15_37_condola2.txt', 'configuracja.py', 'Boson_2022_10_19', 'Monitoring_for_Copy_Processes.json', 'restAPI_exercise.ipynb:Zone.Identifier', 'restapi_FAILDE_PODS.ipynb', 'restapi_ALL.ipynb', 'a.ipynb', 'restAPI_exercise.ipynb', 'reingest.txt', 'configuration_class.py', 'restapi_FAILED_PODS.py', 'api1.py', 'bbbb.txt', 'grafa.json', 'Monitoring_for_Copy_Processes_Copy.json', 'Monitoring_for_Session_Checker_application.json', '.vscode', 'Monitoring_for_FOT_application.json', '15_37_konsola.txt', 'bbbb.json', 'restapi_openshift.ipynb', 'Boson_2022_10_18', 'KPI_806.json', 'reingest2.txt', 'rest_api1.ipynb']\n",
      " DIRECTORIE Boson_2022_10_19 EXISTS \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1473/1691221298.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boson['Name'] = boson['Title'].apply( lambda x : x.replace(\" \",\"_\"))\n",
      "/tmp/ipykernel_1473/1691221298.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boson['Links'] = boson['Uid'].apply( make_link)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 10 19\n",
      "['15_37_plik.txt', 'pody_datapipeline.json', 'res', 'Monitoring_for_Data_Pipeline.json', 'a.py', 'Monitoring_for_Ingest_Service_application.json', 'Monitoring_for_failed_pods_OCP.json', '__pycache__', 'aaa.json', '15_37_condola2.txt', 'configuracja.py', 'Boson_2022_10_19', 'Monitoring_for_Copy_Processes.json', 'restAPI_exercise.ipynb:Zone.Identifier', 'restapi_FAILDE_PODS.ipynb', 'restapi_ALL.ipynb', 'a.ipynb', 'restAPI_exercise.ipynb', 'reingest.txt', 'configuration_class.py', 'restapi_FAILED_PODS.py', 'api1.py', 'bbbb.txt', 'grafa.json', 'Monitoring_for_Copy_Processes_Copy.json', 'Monitoring_for_Session_Checker_application.json', '.vscode', 'Monitoring_for_FOT_application.json', '15_37_konsola.txt', 'bbbb.json', 'restapi_openshift.ipynb', 'Boson_2022_10_18', 'KPI_806.json', 'reingest2.txt', 'rest_api1.ipynb']\n",
      " DIRECTORIE Boson_2022_10_19 EXISTS \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_grafana_dashboards_backups():\n",
    "    TOKEN = \"eyJrIjoiejdFN3hSZ3pva2kwYVE3Mmg0ek1Gc3dxNlh0OWhlUUQiLCJuIjoicmFkZWsiLCJpZCI6Mn0=\"\n",
    "    connection = {\n",
    "        \"proxies\" : {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'},\n",
    "        \"token\" : TOKEN,\n",
    "        \"headers\" : {'Accept': 'application/json',\"Authorization\": \"Bearer \"+ TOKEN},\n",
    "        \"link\"    : \"https://grafana-centralized-monitoring.advantagedp.org/api/search\",\n",
    "        \"linkfolders\"   : \"https://grafana-centralized-monitoring.advantagedp.org/api/folders\",\n",
    "        \"link_db\" : \"https://grafana-centralized-monitoring.advantagedp.org/api/folders/ZsM-EZyZk\", # folder\n",
    "        \"linkf\"   : \"https://grafana-centralized-monitoring.advantagedp.org/api/folders/id/778\",\n",
    "        \"link_search\" : \"https://grafana-centralized-monitoring.advantagedp.org/api/search?query=&\",\n",
    "        \"link_json\"   : \"https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/\"\n",
    "  \n",
    "\n",
    "    }\n",
    "\n",
    "#     mkdir -p dashboards && for dash in $(curl -k -H \"Authorization: Bearer $KEY\" $HOST/api/search\\?query\\=\\& |tr ']' '\\n' |cut -d \",\" -f 5 |grep slug |cut -d\\\" -f 4); do \n",
    "#   curl -k -H \"Authorization: Bearer $KEY\" $HOST/api/dashboards/db/$dash > dashboards/$dash.json \n",
    "# done\n",
    "    res = requests.get(connection['link'], headers=connection['headers'], proxies=connection['proxies'], verify=False)\n",
    "    folders = requests.get(connection['linkfolders'], headers=connection['headers'], proxies=connection['proxies'], verify=False)\n",
    "    # print( 'res ',res )\n",
    "    # print( 'folders ',folders )\n",
    "\n",
    "    res = res.json()\n",
    "    folders = folders.json()\n",
    "    # print( folders )\n",
    "    idF,uidF, titleF, = zip(\n",
    "        *(\n",
    "            (\n",
    "                item[\"id\"],\n",
    "                item[\"uid\"],\n",
    "                item[\"title\"],                \n",
    "            )\n",
    "            for item in folders\n",
    "        )\n",
    "    )\n",
    "    df_folders = pd.DataFrame(\n",
    "        {\n",
    "            \"Id\": idF,\n",
    "            \"Uid\": uidF,\n",
    "            \"Title\": titleF,\n",
    "\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # print(f' \\n {df_folders[0:10]} \\n ')\n",
    "    id,uid, title, uri,url, slug, type_ ,tags, isStarred,  sortMeta = zip(#folderId,folderUid, folderTitle, folderUrl\n",
    "        *(\n",
    "            (\n",
    "                item[\"id\"],\n",
    "                item[\"uid\"],\n",
    "                item[\"title\"],\n",
    "                item[\"uri\"],\n",
    "                item[\"url\"],\n",
    "                item[\"slug\"],\n",
    "                item[\"type\"],\n",
    "                item[\"tags\"],\n",
    "                item[\"isStarred\"],       \n",
    "                item[\"sortMeta\"],\n",
    "                \n",
    "            )\n",
    "            for item in res\n",
    "        )\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Id\": id,\n",
    "            \"Uid\": uid,\n",
    "            \"Title\": title,\n",
    "            \"Uri\": uri,\n",
    "            \"Url\": url,\n",
    "            \"Slug\": slug,\n",
    "            \"Type\": type_,\n",
    "            \"Tags\": tags,\n",
    "            \"IsStarred\": isStarred,\n",
    "            \"SortMeta\": sortMeta,\n",
    "        }\n",
    "    )\n",
    "    # print(  df[0:15:2] ) \n",
    "    # print( df.iloc[12])\n",
    "    boson = df.iloc[12]\n",
    "    df['Boson'] = df['Tags'].apply( lambda x : True if 'boson' in ''.join(x).lower() else False )\n",
    "    boson = df[df['Boson']==True]\n",
    "    def make_link(text , link = connection['link_json']):\n",
    "        return link + text\n",
    "    dir_path = 'Boson'\n",
    "    today = dt.datetime.now()\n",
    "    print( today.year, today.month, str(today.day))\n",
    "    \n",
    "    dir_path = f'{dir_path}_{str(today.year)}_{str(today.month)}_{str(today.day)}'\n",
    "\n",
    "    def make_files(name, link ):\n",
    "        tresc = requests.get(link, headers=connection['headers'], proxies=connection['proxies'], verify=False)\n",
    "        tresc = tresc.json()\n",
    "        name = name + '.json'\n",
    "        with open(name , 'w' , encoding='utf-8') as file:\n",
    "            json.dump( tresc , file)\n",
    "        shutil.copy(name,dir_path)\n",
    "    boson['Name'] = boson['Title'].apply( lambda x : x.replace(\" \",\"_\")) \n",
    "    boson['Links'] = boson['Uid'].apply( make_link)\n",
    "    dir_path = 'Boson'\n",
    "    today = dt.datetime.now()\n",
    "    print( today.year, today.month, str(today.day))\n",
    "    \n",
    "    dir_path = f'{dir_path}_{str(today.year)}_{str(today.month)}_{str(today.day)}'\n",
    "    list_directories = os.listdir()\n",
    "    print( list_directories)\n",
    "    if dir_path  in list_directories:\n",
    "        print( f' DIRECTORIE {dir_path} EXISTS ')\n",
    "    else:\n",
    "        os.mkdir(dir_path)\n",
    "    # print( boson.head() )\n",
    "    for ind in boson.index:\n",
    "        # print( boson['Name'][ind] , boson['Links'][ind] )\n",
    "        make_files(boson['Name'][ind], boson['Links'][ind]  )\n",
    "        \n",
    "\n",
    "    return df , df_folders , boson\n",
    "all_backups, foldery , boson = get_grafana_dashboards_backups()[0]  ,   get_grafana_dashboards_backups()[1] ,get_grafana_dashboards_backups()[2]\n",
    "boson_dashboards = all_dashboardy.loc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id        Uid                               Title  \\\n",
      "493  1927  3Fu2YiQMk                             KPI 806   \n",
      "591  6401  TDuJs5Lnz       Monitoring for Copy Processes   \n",
      "592  6404  EGLqX5Lnk  Monitoring for Copy Processes Copy   \n",
      "593  2786  44lDUgD7z        Monitoring for Data Pipeline   \n",
      "595   435  iWqb0G4Vk      Monitoring for failed pods OCP   \n",
      "\n",
      "                                       Uri  \\\n",
      "493                             db/kpi-806   \n",
      "591       db/monitoring-for-copy-processes   \n",
      "592  db/monitoring-for-copy-processes-copy   \n",
      "593        db/monitoring-for-data-pipeline   \n",
      "595      db/monitoring-for-failed-pods-ocp   \n",
      "\n",
      "                                                 Url Slug     Type     Tags  \\\n",
      "493                             /d/3Fu2YiQMk/kpi-806       dash-db  [Boson]   \n",
      "591       /d/TDuJs5Lnz/monitoring-for-copy-processes       dash-db  [Boson]   \n",
      "592  /d/EGLqX5Lnk/monitoring-for-copy-processes-copy       dash-db  [boson]   \n",
      "593        /d/44lDUgD7z/monitoring-for-data-pipeline       dash-db  [Boson]   \n",
      "595      /d/iWqb0G4Vk/monitoring-for-failed-pods-ocp       dash-db  [Boson]   \n",
      "\n",
      "     IsStarred  SortMeta  Boson  \\\n",
      "493      False         0   True   \n",
      "591      False         0   True   \n",
      "592      False         0   True   \n",
      "593      False         0   True   \n",
      "595      False         0   True   \n",
      "\n",
      "                                                 Links  \\\n",
      "493  https://grafana-centralized-monitoring.advanta...   \n",
      "591  https://grafana-centralized-monitoring.advanta...   \n",
      "592  https://grafana-centralized-monitoring.advanta...   \n",
      "593  https://grafana-centralized-monitoring.advanta...   \n",
      "595  https://grafana-centralized-monitoring.advanta...   \n",
      "\n",
      "                                   Name  \n",
      "493                             KPI_806  \n",
      "591       Monitoring_for_Copy_Processes  \n",
      "592  Monitoring_for_Copy_Processes_Copy  \n",
      "593        Monitoring_for_Data_Pipeline  \n",
      "595      Monitoring_for_failed_pods_OCP  \n",
      "KPI_806 https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/3Fu2YiQMk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring_for_Copy_Processes https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/TDuJs5Lnz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring_for_Copy_Processes_Copy https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/EGLqX5Lnk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring_for_Data_Pipeline https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/44lDUgD7z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring_for_failed_pods_OCP https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/iWqb0G4Vk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring_for_FOT_application https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/A4-k-NYnk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring_for_Ingest_Service_application https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/vJu8sgDnk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring_for_Session_Checker_application https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/Okh3Z3H7k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'grafana-centralized-monitoring.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def get_grafana_dashboards_backups_json():\n",
    "    TOKEN = \"eyJrIjoiejdFN3hSZ3pva2kwYVE3Mmg0ek1Gc3dxNlh0OWhlUUQiLCJuIjoicmFkZWsiLCJpZCI6Mn0=\"\n",
    "    connection = {\n",
    "        \"proxies\" : {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'},\n",
    "        \"token\" : TOKEN,\n",
    "        \"headers\" : {'Accept': 'application/json',\"Authorization\": \"Bearer \"+ TOKEN},\n",
    "        \"link\"    : \"https://grafana-centralized-monitoring.advantagedp.org/api/search\",\n",
    "        \"linkfolders\"   : \"https://grafana-centralized-monitoring.advantagedp.org/api/folders\",\n",
    "        \"link_db\" : \"https://grafana-centralized-monitoring.advantagedp.org/api/folders/ZsM-EZyZk\", # folder\n",
    "        \"linkf\"   : \"https://grafana-centralized-monitoring.advantagedp.org/api/folders/id/778\",\n",
    "        \"link_search\" : \"https://grafana-centralized-monitoring.advantagedp.org/api/search?query=&\",\n",
    "        \"link_json\"   : \"https://grafana-centralized-monitoring.advantagedp.org/api/dashboards/uid/\"\n",
    "    }\n",
    "    def make_link(text , link = connection['link_json']):\n",
    "        return link + text\n",
    "    \n",
    "    def make_files(name, link ):\n",
    "        tresc = requests.get(link, headers=connection['headers'], proxies=connection['proxies'], verify=False)\n",
    "        tresc = tresc.json()\n",
    "        with open(name + '.json', 'w' , encoding='utf-8') as file:\n",
    "            json.dump( tresc , file)\n",
    "            \n",
    "    boson['Name'] = boson['Title'].apply( lambda x : x.replace(\" \",\"_\")) \n",
    "    boson['Links'] = boson['Uid'].apply( make_link)\n",
    "    # print( boson.head() )\n",
    "    for ind in boson.index:\n",
    "        # print( boson['Name'][ind] , boson['Links'][ind] )\n",
    "        make_files(boson['Name'][ind], boson['Links'][ind]  )\n",
    "    return boson\n",
    "    # res = requests.get(connection['link_json'], headers=connection['headers'], proxies=connection['proxies'], verify=False)\n",
    "boson1 = get_grafana_dashboards_backups_json()\n",
    "# for ind in boson.index:\n",
    "#     print( boson['Title'][ind])\n",
    "# print( boson1.iloc[0]['Links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Uid</th>\n",
       "      <th>Title</th>\n",
       "      <th>Uri</th>\n",
       "      <th>Url</th>\n",
       "      <th>Slug</th>\n",
       "      <th>Type</th>\n",
       "      <th>Tags</th>\n",
       "      <th>IsStarred</th>\n",
       "      <th>SortMeta</th>\n",
       "      <th>Boson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1927</td>\n",
       "      <td>3Fu2YiQMk</td>\n",
       "      <td>KPI 806</td>\n",
       "      <td>db/kpi-806</td>\n",
       "      <td>/d/3Fu2YiQMk/kpi-806</td>\n",
       "      <td></td>\n",
       "      <td>dash-db</td>\n",
       "      <td>[Boson]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>6401</td>\n",
       "      <td>TDuJs5Lnz</td>\n",
       "      <td>Monitoring for Copy Processes</td>\n",
       "      <td>db/monitoring-for-copy-processes</td>\n",
       "      <td>/d/TDuJs5Lnz/monitoring-for-copy-processes</td>\n",
       "      <td></td>\n",
       "      <td>dash-db</td>\n",
       "      <td>[Boson]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>6404</td>\n",
       "      <td>EGLqX5Lnk</td>\n",
       "      <td>Monitoring for Copy Processes Copy</td>\n",
       "      <td>db/monitoring-for-copy-processes-copy</td>\n",
       "      <td>/d/EGLqX5Lnk/monitoring-for-copy-processes-copy</td>\n",
       "      <td></td>\n",
       "      <td>dash-db</td>\n",
       "      <td>[boson]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>2786</td>\n",
       "      <td>44lDUgD7z</td>\n",
       "      <td>Monitoring for Data Pipeline</td>\n",
       "      <td>db/monitoring-for-data-pipeline</td>\n",
       "      <td>/d/44lDUgD7z/monitoring-for-data-pipeline</td>\n",
       "      <td></td>\n",
       "      <td>dash-db</td>\n",
       "      <td>[Boson]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>435</td>\n",
       "      <td>iWqb0G4Vk</td>\n",
       "      <td>Monitoring for failed pods OCP</td>\n",
       "      <td>db/monitoring-for-failed-pods-ocp</td>\n",
       "      <td>/d/iWqb0G4Vk/monitoring-for-failed-pods-ocp</td>\n",
       "      <td></td>\n",
       "      <td>dash-db</td>\n",
       "      <td>[Boson]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>6389</td>\n",
       "      <td>A4-k-NYnk</td>\n",
       "      <td>Monitoring for FOT application</td>\n",
       "      <td>db/monitoring-for-fot-application</td>\n",
       "      <td>/d/A4-k-NYnk/monitoring-for-fot-application</td>\n",
       "      <td></td>\n",
       "      <td>dash-db</td>\n",
       "      <td>[boson]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>2783</td>\n",
       "      <td>vJu8sgDnk</td>\n",
       "      <td>Monitoring for Ingest Service application</td>\n",
       "      <td>db/monitoring-for-ingest-service-application</td>\n",
       "      <td>/d/vJu8sgDnk/monitoring-for-ingest-service-app...</td>\n",
       "      <td></td>\n",
       "      <td>dash-db</td>\n",
       "      <td>[Boson]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>2774</td>\n",
       "      <td>Okh3Z3H7k</td>\n",
       "      <td>Monitoring for Session Checker application</td>\n",
       "      <td>db/monitoring-for-session-checker-application</td>\n",
       "      <td>/d/Okh3Z3H7k/monitoring-for-session-checker-ap...</td>\n",
       "      <td></td>\n",
       "      <td>dash-db</td>\n",
       "      <td>[Boson]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id        Uid                                       Title  \\\n",
       "493  1927  3Fu2YiQMk                                     KPI 806   \n",
       "591  6401  TDuJs5Lnz               Monitoring for Copy Processes   \n",
       "592  6404  EGLqX5Lnk          Monitoring for Copy Processes Copy   \n",
       "593  2786  44lDUgD7z                Monitoring for Data Pipeline   \n",
       "595   435  iWqb0G4Vk              Monitoring for failed pods OCP   \n",
       "596  6389  A4-k-NYnk              Monitoring for FOT application   \n",
       "597  2783  vJu8sgDnk   Monitoring for Ingest Service application   \n",
       "598  2774  Okh3Z3H7k  Monitoring for Session Checker application   \n",
       "\n",
       "                                               Uri  \\\n",
       "493                                     db/kpi-806   \n",
       "591               db/monitoring-for-copy-processes   \n",
       "592          db/monitoring-for-copy-processes-copy   \n",
       "593                db/monitoring-for-data-pipeline   \n",
       "595              db/monitoring-for-failed-pods-ocp   \n",
       "596              db/monitoring-for-fot-application   \n",
       "597   db/monitoring-for-ingest-service-application   \n",
       "598  db/monitoring-for-session-checker-application   \n",
       "\n",
       "                                                   Url Slug     Type     Tags  \\\n",
       "493                               /d/3Fu2YiQMk/kpi-806       dash-db  [Boson]   \n",
       "591         /d/TDuJs5Lnz/monitoring-for-copy-processes       dash-db  [Boson]   \n",
       "592    /d/EGLqX5Lnk/monitoring-for-copy-processes-copy       dash-db  [boson]   \n",
       "593          /d/44lDUgD7z/monitoring-for-data-pipeline       dash-db  [Boson]   \n",
       "595        /d/iWqb0G4Vk/monitoring-for-failed-pods-ocp       dash-db  [Boson]   \n",
       "596        /d/A4-k-NYnk/monitoring-for-fot-application       dash-db  [boson]   \n",
       "597  /d/vJu8sgDnk/monitoring-for-ingest-service-app...       dash-db  [Boson]   \n",
       "598  /d/Okh3Z3H7k/monitoring-for-session-checker-ap...       dash-db  [Boson]   \n",
       "\n",
       "     IsStarred  SortMeta  Boson  \n",
       "493      False         0   True  \n",
       "591      False         0   True  \n",
       "592      False         0   True  \n",
       "593      False         0   True  \n",
       "595      False         0   True  \n",
       "596      False         0   True  \n",
       "597      False         0   True  \n",
       "598      False         0   True  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boson = all_backups[all_backups['Boson']==True]\n",
    "# boson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [76], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m( \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mres[meta] \u001b[39m\u001b[39m{\u001b[39;00mres[\u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m key, item \u001b[39min\u001b[39;00m res[\u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m( key , res[\u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m][key] ) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print( f\"res[meta] {res['meta']} \\n \")\n",
    "for key, item in res['meta'].items():\n",
    "    print( key , res['meta'][key] ) \n",
    "print( ' \\n \\n \\n ')   \n",
    "print( f\"res[dashboard] {res['dashboard']} \\n \")\n",
    "for key, item in res['dashboard'].items():\n",
    "    print( key , ' - item  -  ', res['dashboard'][key] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_failed_pods(**kwargs):\n",
    "    # slownik= login_dict2() \n",
    "    auth=HTTPBasicAuth(\n",
    "            BaseHook.get_connection(\"openshift_1\").login,\n",
    "            BaseHook.get_connection(\"openshift_1\").password,\n",
    "        )\n",
    "    os.system(f'oc login https://api.devops.advantagedp.org:6443 -u {auth.username} -p {auth.password}')\n",
    "    TOKEN = subprocess.run(['oc', 'whoami', '-t'], stdout=subprocess.PIPE, stderr=subprocess.PIPE) #stdout=subprocess.PIPE) \n",
    "    TOKEN = TOKEN.stdout.decode().strip()\n",
    "    slownik = {\n",
    "        \"proxies\" : {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'},\n",
    "        \"namespace\" : monitoring_failed_pods_data_pipeline[0]['name'],  #'data-pipeline-monitoring-prod',\n",
    "        \"app_name\" : monitoring_failed_pods_data_pipeline[0]['app_name'],\n",
    "        \"token\" : TOKEN,\n",
    "        'url' :  monitoring_failed_pods_data_pipeline[0]['url'],  #make_endpoint('data-pipeline-monitoring-prod'),\n",
    "        \"headers\" : {'Accept': 'application/json',\"Authorization\": \"Bearer \"+ TOKEN},\n",
    "        \"link\" : 'https://console-openshift-console.apps.devops.advantagedp.org/k8s/ns/data-pipeline-monitoring-prod/pods',\n",
    "    }\n",
    "    # os.system('oc login https://api.devops.advantagedp.org:6443 -u devops_apps_pol-s -p k1.oandvaL3Q7ydJ')\n",
    "    # proxies = {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'}\n",
    "    # TOKEN = 'sha256~wfTI7SW-TKVccd4f_ZEMz2GIWmx2T3l0mOcGjx3CNR0'\n",
    "    # headers = {'Accept': 'application/json',\"Authorization\": \"Bearer \"+ TOKEN}\n",
    "    # url7 = make_endpoint('data-pipeline-monitoring-prod')\n",
    "    # print( url7)\n",
    "    res7 = requests.get(slownik['url'], headers=slownik['headers'], proxies=slownik['proxies'], verify=False)\n",
    "    # res7 = requests.get(url7, headers=headers, proxies=proxies, verify=False)\n",
    "    res_j = res7.json()\n",
    "    df = pd.DataFrame.from_dict(res_j, orient='index')\n",
    "    # res_j\n",
    "    kind,apiVersion, metadata, items = zip(\n",
    "        *(\n",
    "            (\n",
    "                res_j[\"kind\"],\n",
    "                res_j[\"apiVersion\"],\n",
    "                res_j[\"metadata\"],\n",
    "                res_j[\"items\"],\n",
    "            )\n",
    "            for item in res_j\n",
    "        )\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Kind\": kind,\n",
    "            \"ApiVersion\": apiVersion,\n",
    "            \"Metadata\": metadata,\n",
    "            \"Items\": items,\n",
    "        }\n",
    "    )\n",
    "    # print(f'df \\n {df.head(2)}' )\n",
    "\n",
    "    # print( len(res_j['items']))\n",
    "    # print( type(res_j['items'][0]))\n",
    "    df2 = pd.DataFrame(res_j['items'])\n",
    "    # print(f'\\n df2 \\n {df2.head()}' )\n",
    "    now = dt.datetime.now()\n",
    "    # czas = time.strftime()\n",
    "    beauty_time = now.strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "    \n",
    "\n",
    "    name,namespace, creationTimestamp, manageFields_time, status_phase,status_starttime = zip(\n",
    "        *(\n",
    "            (\n",
    "                df2.iloc[idx]['metadata']['name'],       \n",
    "                df2.iloc[idx]['metadata']['namespace'],           \n",
    "                df2.iloc[idx]['metadata']['managedFields'][0]['time'],# to samo   dt.datetime.fromisoformat(df2.iloc[idx]['metadata']['creationTimestamp'][:-1] + '+00:00').strftime(\"%Y-%m-%d  %H:%M:%S\"),            \n",
    "                df2.iloc[idx]['metadata']['managedFields'][0]['time'],# to samo             \n",
    "                df2.iloc[idx]['status']['phase'],            \n",
    "                df2.iloc[idx]['status']['startTime']\n",
    "                \n",
    "                # PONIZEJ BLAD PONIEWAZ df2.iloc[idx]['status']['containerStatuses'][0]['state'] BEDZIE # 3 {'running': {'startedAt': '2022-09-05T07:09:03Z'}}\n",
    "                # 2 {'terminated': {'exitCode': 0, 'reason': 'Completed', 'startedAt': '2022-09-05T07:06:03Z', 'finishedAt': '2022-09-05T07:07:06Z', 'containerID': 'cri-o://c0cc76ca287fe25d23b02d8660c9092b328ee1baa07f1c6b7201f2ad144ee2fc'}}\n",
    "                # df2.iloc[idx]['status']['containerStatuses'][0]['state']['terminated']['reason'],            \n",
    "                # df2.iloc[idx]['status']['containerStatuses'][0]['state']['terminated']['startedAt'],\n",
    "                # df2.iloc[idx]['status']['containerStatuses'][0]['state']['terminated']['finishedAt']\n",
    "                \n",
    "            )\n",
    "            for idx in df2.index\n",
    "        )\n",
    "    )\n",
    "    now = dt.datetime.now()\n",
    "    # czas = time.strftime()\n",
    "    beauty_time = now.strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "    # print(f'now  {now}' )\n",
    "    # print(f'beauty_time {beauty_time}' )\n",
    "    \n",
    "    df3 = pd.DataFrame(\n",
    "        {\n",
    "            \"Name\": name,\n",
    "            \"Namespace\": namespace,\n",
    "            \"CreationTimestamp\": creationTimestamp,\n",
    "            # \"ManageFields_time\": manageFields_time,\n",
    "            \"Status_phase\": status_phase,\n",
    "            # \"Status_startTime\":status_starttime,\n",
    "            \"Time_now\": dt.datetime.now().strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "            # \"Status_starttime\": status_starttime,\n",
    "            # \"Status_containerStatuses_0_state_terminated_reason\": status_containerStatuses_0_state_terminated_reason,\n",
    "            # \"Status_containerStatuses_0_state_terminated_startedAt\": status_containerStatuses_0_state_terminated_startedAt,\n",
    "            # \"Status_containerStatuses_0_state_terminated_finishedAt\": status_containerStatuses_0_state_terminated_finishedAt,\n",
    "        }\n",
    "    )\n",
    "    # print( type(beauty_time))\n",
    "    \n",
    "    df3['App_name'] = df3['Name'].apply(lambda x : '-'.join(x.split('-')[:-2]))\n",
    "    df3['Creation_time'] = df3['CreationTimestamp'].apply(change_creationtimestamp)\n",
    "    df3['Date_diff_hours'] = df3['Creation_time'].apply(difference_dates_hours)\n",
    "    df3['Date_diff_min'] = df3['Creation_time'].apply(difference_dates_minutes)\n",
    "    df3['Link'] = df3['Name'].apply(lambda x : '/'.join([slownik['link'],x]))\n",
    "    print(f'\\n df3 \\n {df3.iloc[0:]}' )\n",
    "    print( df3['Link'].iloc[0])\n",
    "    # print(f'\\n df3 \\n {df3.head()}' )\n",
    "    error = 'Failed'\n",
    "    errory = df3.loc[df3[\"Status_phase\"]  ==  error ]\n",
    "    output_errors = pd.DataFrame(errory, columns=['Name','Namespace','App_name','Status_phase','Creation_time','Date_diff_hours'])\n",
    "    \n",
    "    output_errors = output_errors[output_errors['Date_diff_hours'] <= 24]\n",
    "    print(f'\\n output_errors \\n {output_errors.iloc[0:5]}' )\n",
    "    # output_errors.sort_values(by=['Date_diff_hours'], ascending=False, inplace=True)\n",
    "    # errory_male = errory.head()\n",
    "    # print( f'\\n \\n Pods with status Failed  \\n {errory}     ')\n",
    "    output_errors_html = output_errors.to_html()\n",
    "    \n",
    "\n",
    "    running = 'Running'\n",
    "    runningi = df3.loc[df3[\"Status_phase\"]  ==  running ]\n",
    "    print(f'\\n PRZED  runningi \\n {runningi.iloc[0:5]}' )\n",
    "    runningi = runningi[runningi['Date_diff_hours'] <= 24]\n",
    "    list_running_pods_longer_24 = runningi.index.value_counts()\n",
    "    \n",
    "    print( 'LISTA ',list_running_pods_longer_24)\n",
    "    print(f'\\n PO  runningi \\n {runningi.iloc[0:5]}' )\n",
    "    runnigni_html = runningi.to_html\n",
    "    \n",
    "    # if len(list_running_pods_longer_24) == 0:\n",
    "    #     message = 'no long running pods'\n",
    "    # else:\n",
    "    #     message=\"something important to write if you need \"\n",
    "    # output_html = output_errors_html + \\\n",
    "    #     \"<br/>{}<br/>\".format(message)\n",
    "        \n",
    "    errory_html = errory.to_html\n",
    "    # print(f'   ERRORY TO JSON \\n {errory.to_json}' )\n",
    "    # print( errory_html)\n",
    "    # print( runnigni_html )\n",
    "    errory_json = output_errors.to_json(orient=\"split\")\n",
    "    errory_json2 = errory.to_json(orient=\"split\")\n",
    "    parsed = json.loads(errory_json2)\n",
    "    # print( json.dumps(parsed,indent=4))\n",
    "    ####### !!!!!!!!!!!!!!!!!!!!!!!\n",
    "    # kwargs[\"ti\"].xcom_push(key=\"key\", value=output_html)#errory_male_html)\n",
    "    # PRZY RETURN WARTOSCI WYSKAKIWAL BLAD ZE METODA NIE JEST ITEROWALNA\n",
    "    # ?\n",
    "    # RETURN MUSI BYC NAZWA TASKA team_task_ CZYLI TAK JAK \n",
    "    # NAZWALES TASKA DO WYSYLANIA WIADOMOSCI \n",
    "    #return 'teams_task_'#errory_html\n",
    "    return output_errors #return 'teams_task_'#errory_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " JESTESM PLIKIEM devops_monitoring_FAILED_PODS \n",
      " \n",
      " \n",
      " LONG RUNNING PODS \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(' JESTESM PLIKIEM devops_monitoring_FAILED_PODS ')\n",
    "print( f' \\n \\n LONG RUNNING PODS \\n \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_running_pods( long_time_running=6 , **kwargs):\n",
    "    auth=HTTPBasicAuth(\n",
    "            BaseHook.get_connection(\"openshift_1\").login,\n",
    "            BaseHook.get_connection(\"openshift_1\").password,\n",
    "        )\n",
    "    os.system(f'oc login https://api.devops.advantagedp.org:6443 -u {auth.username} -p {auth.password}')\n",
    "    TOKEN = subprocess.run(['oc', 'whoami', '-t'], stdout=subprocess.PIPE, stderr=subprocess.PIPE) #stdout=subprocess.PIPE) \n",
    "    TOKEN = TOKEN.stdout.decode().strip()\n",
    "    slownik = {\n",
    "        \"proxies\" : {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'},\n",
    "        \"namespace\" : monitoring_failed_pods_data_pipeline[0]['name'],  #'data-pipeline-monitoring-prod',\n",
    "        \"token\" : TOKEN,\n",
    "        'url' :  monitoring_failed_pods_data_pipeline[0]['url'],  #make_endpoint('data-pipeline-monitoring-prod'),\n",
    "        \"headers\" : {'Accept': 'application/json',\"Authorization\": \"Bearer \"+ TOKEN}\n",
    "    }\n",
    "    # url7 = make_endpoint(NAMESPACE)\n",
    "    # res7 = requests.get(url7, headers=headers, proxies=proxies , verify=False)\n",
    "    res7 = requests.get(slownik['url'], headers=slownik['headers'], proxies=slownik['proxies'], verify=False)\n",
    "    res_j = res7.json()\n",
    "    df = pd.DataFrame.from_dict(res_j, orient='index')\n",
    "    kind,apiVersion, metadata, items = zip(\n",
    "        \n",
    "        *(\n",
    "            (\n",
    "                res_j[\"kind\"],\n",
    "                res_j[\"apiVersion\"],\n",
    "                res_j[\"metadata\"],\n",
    "                res_j[\"items\"],\n",
    "            )\n",
    "            for item in res_j\n",
    "        )\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Kind\": kind,\n",
    "            \"ApiVersion\": apiVersion,\n",
    "            \"Metadata\": metadata,\n",
    "            \"Items\": items,\n",
    "        }\n",
    "    )\n",
    "    # print(f' \\t df \\n {df.head()}' )\n",
    "    # print( ' * ' * 20 )\n",
    "    df2 = pd.DataFrame(res_j['items'])\n",
    "    # print(f'\\n df2 \\n {df2.head(15)}' )\n",
    "    now = dt.datetime.now()\n",
    "    # czas = time.strftime()\n",
    "    beauty_time = now.strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "    \n",
    "    name,namespace, creationTimestamp, manageFields_time, status_phase,status_starttime = zip(\n",
    "        *(\n",
    "            (\n",
    "                df2.iloc[idx]['metadata']['name'],       \n",
    "                df2.iloc[idx]['metadata']['namespace'],           \n",
    "                df2.iloc[idx]['metadata']['creationTimestamp'],\n",
    "                df2.iloc[idx]['metadata']['managedFields'][0]['time'],# to samo             \n",
    "                df2.iloc[idx]['status']['phase'],            \n",
    "                df2.iloc[idx]['status']['startTime']\n",
    "                # datetime.fromisoformat(df2.iloc[idx]['metadata']['creationTimestamp'][:-1] + '+00:00').strftime(\"%Y-%m-%d  %H:%M:%S\"),            \n",
    "                # PONIZEJ BLAD PONIEWAZ df2.iloc[idx]['status']['containerStatuses'][0]['state'] BEDZIE # 3 {'running': {'startedAt': '2022-09-05T07:09:03Z'}}\n",
    "                # 2 {'terminated': {'exitCode': 0, 'reason': 'Completed', 'startedAt': '2022-09-05T07:06:03Z', 'finishedAt': '2022-09-05T07:07:06Z', 'containerID': 'cri-o://c0cc76ca287fe25d23b02d8660c9092b328ee1baa07f1c6b7201f2ad144ee2fc'}}\n",
    "                # df2.iloc[idx]['status']['containerStatuses'][0]['state']['terminated']['reason'],            \n",
    "                # df2.iloc[idx]['status']['containerStatuses'][0]['state']['terminated']['startedAt'],\n",
    "                # df2.iloc[idx]['status']['containerStatuses'][0]['state']['terminated']['finishedAt']\n",
    "                \n",
    "            )\n",
    "            for idx in df2.index\n",
    "        )\n",
    "    )\n",
    "    now = dt.datetime.now()\n",
    "    # czas = time.strftime()\n",
    "    beauty_time = now.strftime(\"%Y-%m-%d  %H:%M:%S\")\n",
    "    # print(f'now  {now}' )\n",
    "    # print(f'beauty_time {beauty_time}' )\n",
    "    \n",
    "    df3 = pd.DataFrame(\n",
    "        {\n",
    "            \"Name\": name,\n",
    "            \"Namespace\": namespace,\n",
    "            \"CreationTimestamp\": creationTimestamp,\n",
    "            # \"ManageFields_time\": manageFields_time,\n",
    "            \"Status_phase\": status_phase,\n",
    "            \"Time_now\": dt.datetime.now().strftime(\"%Y-%m-%d  %H:%M:%S\"),\n",
    "            # \"Status_starttime\": status_starttime,\n",
    "            # \"Status_containerStatuses_0_state_terminated_reason\": status_containerStatuses_0_state_terminated_reason,\n",
    "            # \"Status_containerStatuses_0_state_terminated_startedAt\": status_containerStatuses_0_state_terminated_startedAt,\n",
    "            # \"Status_containerStatuses_0_state_terminated_finishedAt\": status_containerStatuses_0_state_terminated_finishedAt,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \n",
    "    df3['App_name'] = df3['Name'].apply(lambda x : '-'.join(x.split('-')[:-2]))\n",
    "    df3['Creation_time'] = df3['CreationTimestamp'].apply(change_creationtimestamp)\n",
    "    df3['Date_diff_hours'] = df3['Creation_time'].apply(difference_dates_hours)\n",
    "    df3['Date_diff_min'] = df3['Creation_time'].apply(difference_dates_minutes)\n",
    "    print( type(beauty_time))\n",
    "    print(f'\\n df3 \\n {df3.iloc[0:50]}' )\n",
    "    # print(f'\\n  \\t df3 \\n {df3}' )\n",
    "    error = 'Failed'\n",
    "    errory = df3.loc[df3[\"Status_phase\"]  ==  error ]\n",
    "\n",
    "    errory_html = errory.to_html\n",
    "\n",
    "    running = 'Running'\n",
    "    runningi = df3.loc[df3[\"Status_phase\"]  ==  running ]\n",
    "    boson='dpm-dxc-boson'\n",
    "    runningi = runningi.loc[runningi['Name'] != boson ]\n",
    "    output_running = pd.DataFrame(runningi, columns=['Name','Namespace','App_name','Status_phase','Creation_time','Date_diff_min'])\n",
    "    output_runnigni_html = output_running.to_html()\n",
    "    message=\"something important to write if you need \"\n",
    "    output_html = output_runnigni_html + \\\n",
    "        \"<br/>{}<br/>\".format(message)\n",
    "    \n",
    "\n",
    "    errory_html = errory.to_html\n",
    "    print( ' errory lista indexo ')\n",
    "    print( errory.index.values )\n",
    "    print( ' runningi lista indexo ')\n",
    "    print( output_running.index.values )\n",
    "    # kwargs[\"ti\"].xcom_push(key=\"key\", value=output_html)#errory_male_html)\n",
    "    # PRZY RETURN WARTOSCI WYSKAKIWAL BLAD ZE METODA NIE JEST ITEROWALNA\n",
    "    # ?\n",
    "    # RETURN MUSI BYC NAZWA TASKA team_task_ CZYLI TAK JAK \n",
    "    # NAZWALES TASKA DO WYSYLANIA WIADOMOSCI \n",
    "    # return 'teams_task_' \n",
    "    return output_running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " AIRFLOW_RESTAPI \n",
      " \n",
      " \n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "SOCKSHTTPSConnectionPool(host='airflow-prod.dplapps.advantagedp.org', port=443): Max retries exceeded with url: /api/experimental/dags/ingest/dag_runs (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x7fb2b56e3430>: Failed to establish a new connection: Connection closed unexpectedly'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGeneralProxyError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/socks.py:809\u001b[0m, in \u001b[0;36msocksocket.connect\u001b[0;34m(self, dest_pair, catch_errors)\u001b[0m\n\u001b[1;32m    808\u001b[0m     negotiate \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_proxy_negotiators[proxy_type]\n\u001b[0;32m--> 809\u001b[0m     negotiate(\u001b[39mself\u001b[39;49m, dest_addr, dest_port)\n\u001b[1;32m    810\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/socks.py:443\u001b[0m, in \u001b[0;36msocksocket._negotiate_SOCKS5\u001b[0;34m(self, *dest_addr)\u001b[0m\n\u001b[1;32m    442\u001b[0m CONNECT \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy_peername, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy_sockname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_SOCKS5_request(\n\u001b[1;32m    444\u001b[0m     \u001b[39mself\u001b[39;49m, CONNECT, dest_addr)\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/socks.py:524\u001b[0m, in \u001b[0;36msocksocket._SOCKS5_request\u001b[0;34m(self, conn, cmd, dst)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39m# Get the response\u001b[39;00m\n\u001b[0;32m--> 524\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_readall(reader, \u001b[39m3\u001b[39;49m)\n\u001b[1;32m    525\u001b[0m \u001b[39mif\u001b[39;00m resp[\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\x05\u001b[39;00m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/socks.py:278\u001b[0m, in \u001b[0;36msocksocket._readall\u001b[0;34m(self, file, count)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m d:\n\u001b[0;32m--> 278\u001b[0m     \u001b[39mraise\u001b[39;00m GeneralProxyError(\u001b[39m\"\u001b[39m\u001b[39mConnection closed unexpectedly\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    279\u001b[0m data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m d\n",
      "\u001b[0;31mGeneralProxyError\u001b[0m: Connection closed unexpectedly",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGeneralProxyError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/urllib3/contrib/socks.py:90\u001b[0m, in \u001b[0;36mSOCKSConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     conn \u001b[39m=\u001b[39m socks\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m     91\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhost, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m     92\u001b[0m         proxy_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39msocks_version\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     93\u001b[0m         proxy_addr\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39mproxy_host\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     94\u001b[0m         proxy_port\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39mproxy_port\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     95\u001b[0m         proxy_username\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39musername\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     96\u001b[0m         proxy_password\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39mpassword\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     97\u001b[0m         proxy_rdns\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_socks_options[\u001b[39m\"\u001b[39;49m\u001b[39mrdns\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     98\u001b[0m         timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m     99\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/socks.py:209\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(dest_pair, timeout, source_address, proxy_type, proxy_addr, proxy_port, proxy_rdns, proxy_username, proxy_password, socket_options)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m err:\n\u001b[0;32m--> 209\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m    211\u001b[0m \u001b[39mraise\u001b[39;00m socket\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mgai returned empty list.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/socks.py:199\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(dest_pair, timeout, source_address, proxy_type, proxy_addr, proxy_port, proxy_rdns, proxy_username, proxy_password, socket_options)\u001b[0m\n\u001b[1;32m    197\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 199\u001b[0m sock\u001b[39m.\u001b[39;49mconnect((remote_host, remote_port))\n\u001b[1;32m    200\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/socks.py:47\u001b[0m, in \u001b[0;36mset_self_blocking.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetblocking(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     48\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/socks.py:814\u001b[0m, in \u001b[0;36msocksocket.connect\u001b[0;34m(self, dest_pair, catch_errors)\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n\u001b[0;32m--> 814\u001b[0m     \u001b[39mraise\u001b[39;00m GeneralProxyError(\u001b[39m\"\u001b[39m\u001b[39mSocket error\u001b[39m\u001b[39m\"\u001b[39m, error)\n\u001b[1;32m    815\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mGeneralProxyError\u001b[0m: Socket error: Connection closed unexpectedly",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:670\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 670\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    671\u001b[0m     conn,\n\u001b[1;32m    672\u001b[0m     method,\n\u001b[1;32m    673\u001b[0m     url,\n\u001b[1;32m    674\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    675\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    676\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    677\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    678\u001b[0m )\n\u001b[1;32m    680\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:381\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    382\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    383\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:978\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m--> 978\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    980\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/urllib3/connection.py:309\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    308\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    310\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/urllib3/contrib/socks.py:121\u001b[0m, in \u001b[0;36mSOCKSConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m         \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    122\u001b[0m             \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m error\n\u001b[1;32m    123\u001b[0m         )\n\u001b[1;32m    124\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x7fb2b56e3430>: Failed to establish a new connection: Connection closed unexpectedly",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/requests/adapters.py:439\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 439\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    440\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    441\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    442\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    443\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    444\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    445\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    449\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    450\u001b[0m     )\n\u001b[1;32m    452\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:726\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    724\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 726\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    727\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    728\u001b[0m )\n\u001b[1;32m    729\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/urllib3/util/retry.py:446\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    448\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: SOCKSHTTPSConnectionPool(host='airflow-prod.dplapps.advantagedp.org', port=443): Max retries exceeded with url: /api/experimental/dags/ingest/dag_runs (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x7fb2b56e3430>: Failed to establish a new connection: Connection closed unexpectedly'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mprint\u001b[39m( \u001b[39m'\u001b[39m\u001b[39m ok \u001b[39m\u001b[39m'\u001b[39m )\n\u001b[1;32m     59\u001b[0m     \u001b[39m# return df\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m airflow_restapi()\n",
      "Cell \u001b[0;32mIn [5], line 20\u001b[0m, in \u001b[0;36mairflow_restapi\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m slownik \u001b[39m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mproxies\u001b[39m\u001b[39m\"\u001b[39m : {\u001b[39m'\u001b[39m\u001b[39mhttp\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msocks5h://192.168.67.2:1081\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttps\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msocks5h://192.168.67.2:1081\u001b[39m\u001b[39m'\u001b[39m},\n\u001b[1;32m     12\u001b[0m     \u001b[39m# 'auth' : HTTPBasicAuth('ingest_pipeline-s', '1Rt.d5WssojT.2'),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39mhttps://airflow-prod.dplapps.advantagedp.org/api/experimental/dags/ingest/dag_runs\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[39m# url7 = make_endpoint(NAMESPACE)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# res7 = requests.get(url7, headers=headers, proxies=proxies , verify=False)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m res7 \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(slownik[\u001b[39m'\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m'\u001b[39;49m], auth\u001b[39m=\u001b[39;49mauth, proxies\u001b[39m=\u001b[39;49mslownik[\u001b[39m'\u001b[39;49m\u001b[39mproxies\u001b[39;49m\u001b[39m'\u001b[39;49m], verify\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     23\u001b[0m res_j \u001b[39m=\u001b[39m res7\u001b[39m.\u001b[39mjson()\n\u001b[1;32m     24\u001b[0m \u001b[39m# df = pd.DataFrame.from_dict(res_j, orient='index')\u001b[39;00m\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/requests/api.py:76\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m'\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/requests/sessions.py:530\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    525\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    527\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    528\u001b[0m }\n\u001b[1;32m    529\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 530\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    532\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/requests/sessions.py:643\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    642\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    645\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    646\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/venv2airflow/lib/python3.8/site-packages/requests/adapters.py:516\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    513\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 516\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    518\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: SOCKSHTTPSConnectionPool(host='airflow-prod.dplapps.advantagedp.org', port=443): Max retries exceeded with url: /api/experimental/dags/ingest/dag_runs (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x7fb2b56e3430>: Failed to establish a new connection: Connection closed unexpectedly'))"
     ]
    }
   ],
   "source": [
    "print( f' \\n \\n AIRFLOW_RESTAPI \\n \\n ')\n",
    "# https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html#operation/get_tasks\n",
    "def airflow_restapi():\n",
    "    # auth=HTTPBasicAuth(\n",
    "    #         BaseHook.get_connection(\"openshift_1\").login,\n",
    "    #         BaseHook.get_connection(\"openshift_1\").password,\n",
    "    #     )\n",
    "    auth = HTTPBasicAuth('ingest_pipeline-s', '1Rt.d5WssojT.2')\n",
    "\n",
    "    slownik = {\n",
    "        \"proxies\" : {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'},\n",
    "        # 'auth' : HTTPBasicAuth('ingest_pipeline-s', '1Rt.d5WssojT.2'),\n",
    "        'url' :  \"https://airflow-prod.apps.devops.advantagedp.org/api/experimental/dags/session_checker/dag_runs\",\n",
    "        # 'url' :  \"https://airflow-prod.apps.devops.advantagedp.org/api/experimental/dags/data_pipeline/dag_runs\",\n",
    "        # 'url' :  \"https://airflow-prod.apps.devops.advantagedp.org/api/experimental/dags/data_pipeline/tasks/sq-1665644773469_6e442987-b741-412f-a9d4-0183ad84cac7\",\n",
    "        # 'url' : \"https://airflow-prod.dplapps.advantagedp.org/api/experimental/dags/ingest/dag_runs\"\n",
    "    }\n",
    "    # url7 = make_endpoint(NAMESPACE)\n",
    "    # res7 = requests.get(url7, headers=headers, proxies=proxies , verify=False)\n",
    "    res7 = requests.get(slownik['url'], auth=auth, proxies=slownik['proxies'], verify=False)\n",
    "\n",
    "    \n",
    "    res_j = res7.json()\n",
    "    # df = pd.DataFrame.from_dict(res_j, orient='index')\n",
    "    print( 'ffffff \\n \\n ')\n",
    "    print( res_j)\n",
    "    print( type(res_j))\n",
    "    for i, el in enumerate(res_j):\n",
    "        print(i, el )\n",
    "    dag_id,dag_run_url, execution_date, id,run_id, start_date,state = zip(\n",
    "        *(\n",
    "            (\n",
    "                item[\"dag_id\"],\n",
    "                item[\"dag_run_url\"],\n",
    "                item[\"execution_date\"],\n",
    "                item[\"id\"],\n",
    "                item[\"run_id\"],\n",
    "                item[\"start_date\"],\n",
    "                item[\"state\"],\n",
    "            \n",
    "                \n",
    "            )\n",
    "            for item in res_j\n",
    "        )\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Dag_id\" :  dag_id,\n",
    "            \"Dag_run_url\" :  dag_run_url,\n",
    "            \"Execution_date\" :  execution_date,\n",
    "            \"Id\" :  id,\n",
    "            \"Run_id\" :  run_id,\n",
    "            \"Start_date\" :  start_date,\n",
    "            \"State\" :  state,\n",
    "        }\n",
    "    )\n",
    "    df['Execution_date_2'] = df['Execution_date'].apply(lambda x : dt.datetime.fromisoformat(x[:-1] + '+00:00') )\n",
    "    print( ' ok ' )\n",
    "    # return df\n",
    "airflow_restapi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_success_date(dag_id, username, default_return_value='now-12h'):\n",
    "    '''\n",
    "    Takes dag_id and airflow username and using airflow api returns timedate of the last successful run in format accepted by the elasticsearch api\n",
    "    default_return_value is optional and set for 12 hours behind. Value MUST be a proper elasticsearch date format, i.e. 'now-12h' or '2022-05-10T12:00:00' for more: https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html\n",
    "    '''\n",
    "    endpoint_url = \"https://airflow-prod.apps.devops.advantagedp.org/api/experimental/dags/\"+dag_id+\"/dag_runs\"\n",
    "    credentials = {\n",
    "        \"username\": BaseHook.get_connection(username).login,\n",
    "        \"password\": \"z56fCgvBq6ECBomi\",#BaseHook.get_connection(username).password,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = get(endpoint_url, auth=(credentials.get(\n",
    "            'username'), credentials.get('password')))\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                \"Airflow api returned !=200 status, raising exception\")\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise AirflowException(\"Connection to the Airflow api failed\") from err\n",
    "    dag_runs_df = pd.DataFrame(json.loads(response.text))\n",
    "    dag_runs_df = dag_runs_df[dag_runs_df.state == 'success']\n",
    "\n",
    "    if dag_runs_df.empty:\n",
    "        print('No previous successful runs, default: ' + default_return_value)\n",
    "        return default_return_value\n",
    "    else:\n",
    "        last_success_run = dag_runs_df.iloc[-1:]\n",
    "        start_date = last_success_run['start_date'].values[0]\n",
    "        start_date = start_date[0:19]\n",
    "        print('Last successful run date: '+start_date)\n",
    "        return start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_success_date_epoch(dag_id, username='ingest_pipeline-s', default_return_hours=12, in_seconds=False):\n",
    "    '''\n",
    "    Takes dag_id and airflow username and using airflow api returns timedate of the last successful run in epoch miliseconds (seconds if in_seconds = True)\n",
    "    IMPORTANT: default_return_hours is optional and set for 12 hours behind. Value describes how many hours substract from current date if no successful runs before has been found for this dag \n",
    "    OUTPUT: epoch time in miliseconds or seconds\n",
    "    '''\n",
    "    endpoint_url = \"https://airflow-prod.apps.devops.advantagedp.org/api/experimental/dags/\"+dag_id+\"/dag_runs\"\n",
    "    credentials = {\n",
    "        \"username\": 'ingest_pipeline-s',# BaseHook.get_connection(username).login,\n",
    "        \"password\": '1Rt.d5WssojT.2',#BaseHook.get_connection(username).password,\n",
    "    }\n",
    "    ''' DODANE PRZEZE MNIE '''\n",
    "    proxies = {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'}\n",
    "    auth = HTTPBasicAuth('ingest_pipeline-s', '1Rt.d5WssojT.2')\n",
    "\n",
    "    slownik = {\n",
    "        \"proxies\" : {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'},\n",
    "        # 'auth' : HTTPBasicAuth('ingest_pipeline-s', '1Rt.d5WssojT.2'),\n",
    "        'url' :  \"https://airflow-prod.apps.devops.advantagedp.org/api/experimental/dags/session_checker/dag_runs\",\n",
    "    }\n",
    "    res7 = requests.get(slownik['url'], auth=auth, proxies=slownik['proxies'], verify=False)\n",
    "    ''' DODANE PRZEZE MNIE '''\n",
    "    try:\n",
    "        # response = get(endpoint_url, auth=(credentials.get(\n",
    "        #     'username'), credentials.get('password')),proxies=proxies)\n",
    "        response = requests.get(slownik['url'], auth=auth, proxies=slownik['proxies'], verify=False)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\n",
    "                \"Airflow api returned !=200 status, raising exception\")\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        raise AirflowException(\"Connection to the Airflow api failed\") from err\n",
    "\n",
    "    dag_runs_df = pd.DataFrame(json.loads(response.text))\n",
    "    dag_runs_df = dag_runs_df[dag_runs_df.state == 'success']\n",
    "\n",
    "    if dag_runs_df.empty:\n",
    "        epoch_time = int(time.time() - 3600 * default_return_hours)\n",
    "        if in_seconds == False:\n",
    "            epoch_time = epoch_time * 1000\n",
    "\n",
    "        print('No previous successful runs, default: ' + str(epoch_time))\n",
    "        return epoch_time\n",
    "    else:\n",
    "        last_success_run = dag_runs_df.iloc[-1:]\n",
    "        start_date = last_success_run['start_date'].values[0]\n",
    "        start_date = parse(start_date)\n",
    "        epoch_start_date = calendar.timegm(start_date.utctimetuple())\n",
    "        print('Last successful run date: '+str(dt.datetime.utcfromtimestamp(\n",
    "            epoch_start_date).strftime('%Y-%m-%d %H:%M:%S')))\n",
    "\n",
    "        if in_seconds == False:\n",
    "            epoch_start_date = epoch_start_date*1000\n",
    "            print('Last successful run date in epoch miliseconds: ' +\n",
    "                  str(epoch_start_date))\n",
    "        else:\n",
    "            print('Last successful run date in epoch seconds: ' +\n",
    "                  str(epoch_start_date))\n",
    "\n",
    "        return epoch_start_date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'airflow-prod.apps.devops.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/home/radekt/venv2airflow/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'airflow-prod.apps.devops.advantagedp.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last successful run date: 2022-09-16 13:14:07\n",
      "Last successful run date in epoch miliseconds: 1663334047000\n",
      "last_success_date_epoch 1663334047000\n"
     ]
    }
   ],
   "source": [
    "print( 'last_success_date_epoch', last_success_date_epoch('auto_labelling', 'ingest_pipeline-s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yarn(**kwargs):\n",
    "    # slownik= login_dict2() \n",
    "    # auth=HTTPBasicAuth(\n",
    "    #         BaseHook.get_connection(\"yarn_1\").login,\n",
    "    #         BaseHook.get_connection(\"yarn_1\").password,\n",
    "    #     )\n",
    "    url = 'https://mapr-web.advantagedp.org:20202/ws/v1/cluster/apps?user=ingest_pipeline-s&finalStatus=SUCCEEDED&startedTimeBegin=1568491200000'\n",
    "    auth = HTTPBasicAuth('ingest_pipeline-s', '1Rt.d5WssojT.2')\n",
    "    slownik = {\n",
    "        \"proxies\" : {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'},\n",
    "        \"namespace\" : monitoring_failed_pods_data_pipeline[0]['name'],  #'data-pipeline-monitoring-prod',\n",
    "        \"app_name\" : monitoring_failed_pods_data_pipeline[0]['app_name'],\n",
    "        'url' :  monitoring_failed_pods_data_pipeline[0]['url'],  #make_endpoint('data-pipeline-monitoring-prod'),\n",
    "    }\n",
    "    aaa = \"https://mapr-web.advantagedp.org:20202\"\n",
    "    proxies = {'http': 'socks5h://192.168.67.2:1081', 'https': 'socks5h://192.168.67.2:1081'}\n",
    "    res7 = requests.get(slownik['url'],  proxies=slownik['proxies'], verify=False)\n",
    "    # res7 = requests.get(url7, headers=headers, proxies=proxies, verify=False)\n",
    "    res_j = res7.json()\n",
    "    df = pd.DataFrame.from_dict(res_j, orient='index')\n",
    "    # res_j\n",
    "    response = requests.get(url, auth=auth, proxies=proxies, verify=False)\n",
    "    response_json = response.json()\n",
    "    response2 = requests.get(url, auth=auth, proxies=proxies, verify=False)\n",
    "    response2_json = response2.json()\n",
    "    # print( response2_json)\n",
    "    df1 = pd.DataFrame(response2_json)\n",
    "    my_list = df1.columns.values.tolist()\n",
    "    # print(my_list)\n",
    "    # print( response2_json)\n",
    "    df1_1 = df1['apps']['app']\n",
    "    print( type(df1_1))\n",
    "    # for el in df1_1:\n",
    "    #     print( el, ' \\n ' , type(el), ' \\n ')\n",
    "    print( df1_1[0].keys() )\n",
    "    # print(len(df1_1))\n",
    "    # names, ids, trackingUrls, diagnostics, queues = zip(\n",
    "    #     *(\n",
    "    #         (\n",
    "    #             item[\"name\"],\n",
    "    #             item[\"id\"],\n",
    "    #             item[\"trackingUrl\"],\n",
    "    #             item[\"diagnostics\"],\n",
    "    #             item[\"queue\"],\n",
    "    #         )\n",
    "    #         for item in response_json[\"apps\"][\"app\"]\n",
    "    #     )\n",
    "    # )\n",
    "    names, ids, users, names, queues, states, finalStatuss, progresss, trackingUIs, trackingUrls, diagnosticss, clusterIds, applicationTypes, applicationTagss, startedTimes, finishedTimes, elapsedTimes, amContainerLogss, amHostHttpAddresss, allocatedMBs, allocatedVCoress, runningContainerss, memorySecondss,vcoreSecondss, preemptedResourceMBs, preemptedResourceVCoress, numNonAMContainerPreempteds, numAMContainerPreempteds = zip(\n",
    "        *(\n",
    "            (\n",
    "                item[\"name\"],\n",
    "                item[\"id\"],\n",
    "                item[\"user\"],\n",
    "                item[\"name\"],\n",
    "                item[\"queue\"],\n",
    "                item[\"state\"],\n",
    "                item[\"finalStatus\"],\n",
    "                item[\"progress\"],\n",
    "                item[\"trackingUI\"],\n",
    "                item[\"trackingUrl\"],\n",
    "                item[\"diagnostics\"],\n",
    "                item[\"clusterId\"],\n",
    "                item[\"applicationType\"],\n",
    "                item[\"applicationTags\"],\n",
    "                item[\"startedTime\"],\n",
    "                item[\"finishedTime\"],\n",
    "                item[\"elapsedTime\"],\n",
    "                item[\"amContainerLogs\"],\n",
    "                item[\"amHostHttpAddress\"],\n",
    "                item[\"allocatedMB\"],\n",
    "                item[\"allocatedVCores\"],\n",
    "                item[\"runningContainers\"],\n",
    "                item[\"memorySeconds\"],\n",
    "                item[\"vcoreSeconds\"],\n",
    "                item[\"preemptedResourceMB\"],\n",
    "                item[\"preemptedResourceVCores\" ],\n",
    "                item[\"numNonAMContainerPreempted\"],\n",
    "                item[\"numAMContainerPreempted\"],\n",
    "            )\n",
    "            for item in response_json[\"apps\"][\"app\"]\n",
    "        )\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"Names\"  :names  ,      \n",
    "            \"Users\" :users,\n",
    "            \"Ids\" :  ids ,\n",
    "            \"Queues\" :    queues ,\n",
    "            \"States\" :     states,\n",
    "            \"FinalStatuss\" :  finalStatuss ,    \n",
    "            \"Progresss\" :  progresss , \n",
    "            \"TrackingUIs\" :   trackingUIs,\n",
    "            \"TrackingUrls\" :   trackingUrls , \n",
    "            \"Diagnosticss\"  :   diagnosticss  ,  \n",
    "            \"ClusterIds\" :    clusterIds,\n",
    "            \"ApplicationTypes\" :   applicationTypes,\n",
    "            \"ApplicationTagss\" :   applicationTagss , \n",
    "            \"StartedTimes\"  :    startedTimes ,\n",
    "            \"FinishedTimes\"  :     finishedTimes  ,\n",
    "            \"ElapsedTimes\" :    elapsedTimes,\n",
    "            \"AmContainerLogss\" :   amContainerLogss,\n",
    "            \"AmHostHttpAddresss\"  :    amHostHttpAddresss,\n",
    "            \"AllocatedMBs\"  :    allocatedMBs,\n",
    "            \"AllocatedVCoress\"  :   allocatedVCoress ,   \n",
    "            \"MemorySecondss\" :    memorySecondss,\n",
    "            \"VcoreSecondss\" :   vcoreSecondss,\n",
    "            \"PreemptedResourceMBs\"  :    preemptedResourceMBs,\n",
    "            \"PreemptedResourceVCoress\"  :     preemptedResourceVCoress , \n",
    "            \"NumNonAMContainerPreempteds\"  :  numNonAMContainerPreempteds,\n",
    "            \"NumAMContainerPreempteds\" :   numAMContainerPreempteds,\n",
    "        }\n",
    "    )   \n",
    "    print( df.head())\n",
    "\n",
    "    return ':)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( difference_dates_hours()   )     #   def difference_dates_hours(date1)   \n",
    "# print( difference_dates_minutes() )     #   def difference_dates_minutes(date1)\n",
    "# print( difference_dates_seconds() )     #   def difference_dates_seconds(date1) \n",
    "# print( change_creationtimestamp() )     #   def change_creationtimestamp(date)\n",
    "\n",
    "\n",
    "# print( date_to_epoch()            )   #def date_to_epoch(date_input, in_seconds=False)\n",
    "# print( get_failed_pods()          )   #def get_failed_pods(**kwargs)\n",
    "# print( get_long_running_pods()    )   #def get_long_running_pods( long_time_running=6 , **kwargs)\n",
    "# print( airflow_restapi()          )   #def airflow_restapi()\n",
    "# print( last_success_date()        )   #def last_success_date(dag_id, username, default_return_value='now-12h')\n",
    "# print( last_success_date_epoch()  )   # def last_success_date_epoch(dag_id, username='ingest_pipeline-s', default_return_hours=12, in_seconds=False)\n",
    "# print( get_yarn()  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('venv2airflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "830a681f0e600863535f4d54d8def7b235912edc63749029f978fa66da05c05b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
